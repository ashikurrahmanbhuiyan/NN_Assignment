{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INZgXZJdmWUs"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "input_video = \"video.mp4\"\n",
        "output_video = \"output_detected.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model.predict(source=frame, imgsz=640, conf=0.25, verbose=False)\n",
        "    for result in results:\n",
        "        annotated_frame = result.plot()\n",
        "\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbtFRVp0g5GM",
        "outputId": "1b5bc3a4-b153-4989-e374-a679df1c3d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished processing with yolov8n\n",
            "Finished processing with yolo11n\n",
            "Finished processing with yolo12n\n",
            "\n",
            "--- Model Performance Comparison ---\n",
            "\n",
            "Model: yolov8n\n",
            "  Total Inference Time: 91.54 seconds\n",
            "  Frames Processed: 472\n",
            "  Calculated FPS: 5.16\n",
            "\n",
            "Model: yolo11n\n",
            "  Total Inference Time: 72.00 seconds\n",
            "  Frames Processed: 472\n",
            "  Calculated FPS: 6.56\n",
            "\n",
            "Model: yolo12n\n",
            "  Total Inference Time: 91.67 seconds\n",
            "  Frames Processed: 472\n",
            "  Calculated FPS: 5.15\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "video_path = '/content/video.mp4'\n",
        "\n",
        "model_performance = {}\n",
        "\n",
        "for model_name in [\"yolov8n\", \"yolo11n\", \"yolo12n\"]:\n",
        "    try:\n",
        "        model = YOLO(f\"{model_name}.pt\")\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            continue\n",
        "\n",
        "        start_time = time.time()\n",
        "        frames_processed = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = model(frame, verbose=False)\n",
        "            frames_processed += 1\n",
        "\n",
        "        end_time = time.time()\n",
        "        cap.release()\n",
        "\n",
        "        inference_time = end_time - start_time\n",
        "        calculated_fps = frames_processed / inference_time if inference_time > 0 else 0\n",
        "\n",
        "        model_performance[model_name] = {\n",
        "            'inference_time_seconds': inference_time,\n",
        "            'processed_frames': frames_processed,\n",
        "            'calculated_fps': calculated_fps\n",
        "        }\n",
        "        print(f\"Finished processing with {model_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process with model {model_name}: {e}\")\n",
        "        model_performance[model_name] = {'error': str(e)}\n",
        "\n",
        "\n",
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "for model_name, metrics in model_performance.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    if 'error' in metrics:\n",
        "        print(f\"  Status: Error - {metrics['error']}\")\n",
        "    else:\n",
        "        print(f\"  Total Inference Time: {metrics['inference_time_seconds']:.2f} seconds\")\n",
        "        print(f\"  Frames Processed: {metrics['processed_frames']}\")\n",
        "        print(f\"  Calculated FPS: {metrics['calculated_fps']:.2f}\")\n",
        "\n",
        "print(\"------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RaqQxbVpjaDu",
        "outputId": "aafb36de-7487-43b5-995f-ba33083c3903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished detailed object counting for yolov8n\n",
            "Finished detailed object counting for yolo11n\n",
            "Finished detailed object counting for yolo12n\n",
            "\n",
            "--- Model Detailed Object Detection Comparison ---\n",
            "\n",
            "Model: yolov8n\n",
            "  Total Objects Detected Across All Processed Frames: 1814\n",
            "  Frames Processed: 472\n",
            "  Detected Objects and Counts:\n",
            "    - cow: 206\n",
            "    - horse: 406\n",
            "    - giraffe: 122\n",
            "    - elephant: 398\n",
            "    - person: 25\n",
            "    - bird: 480\n",
            "    - zebra: 165\n",
            "    - sheep: 11\n",
            "    - bear: 1\n",
            "\n",
            "Model: yolo11n\n",
            "  Total Objects Detected Across All Processed Frames: 1575\n",
            "  Frames Processed: 472\n",
            "  Detected Objects and Counts:\n",
            "    - cow: 312\n",
            "    - horse: 422\n",
            "    - elephant: 428\n",
            "    - giraffe: 113\n",
            "    - person: 12\n",
            "    - sheep: 1\n",
            "    - bird: 284\n",
            "    - zebra: 3\n",
            "\n",
            "Model: yolo12n\n",
            "  Total Objects Detected Across All Processed Frames: 1687\n",
            "  Frames Processed: 472\n",
            "  Detected Objects and Counts:\n",
            "    - cow: 45\n",
            "    - horse: 773\n",
            "    - person: 9\n",
            "    - giraffe: 113\n",
            "    - elephant: 311\n",
            "    - bird: 436\n",
            "-------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model_detailed_object_counts = {}\n",
        "\n",
        "for model_name in [\"yolov8n\", \"yolo11n\", \"yolo12n\"]:\n",
        "    try:\n",
        "        model = YOLO(f\"{model_name}.pt\")\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file {video_path}\")\n",
        "            model_detailed_object_counts[model_name] = {'error': f\"Could not open video file {video_path}\"}\n",
        "            continue\n",
        "\n",
        "        total_objects_detected = 0\n",
        "        frames_processed = 0\n",
        "        object_class_counts = {}\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            results = model(frame, verbose=False)\n",
        "            for result in results:\n",
        "                if result.boxes is not None:\n",
        "                    total_objects_detected += len(result.boxes)\n",
        "                    for box in result.boxes:\n",
        "                        class_id = int(box.cls[0])\n",
        "                        class_name = model.names[class_id]\n",
        "                        object_class_counts[class_name] = object_class_counts.get(class_name, 0) + 1\n",
        "\n",
        "\n",
        "            frames_processed += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        model_detailed_object_counts[model_name] = {\n",
        "            'total_objects_detected_across_video': total_objects_detected,\n",
        "            'frames_processed': frames_processed,\n",
        "            'object_class_counts': object_class_counts\n",
        "        }\n",
        "        print(f\"Finished detailed object counting for {model_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process with model {model_name}: {e}\")\n",
        "        model_detailed_object_counts[model_name] = {'error': str(e)}\n",
        "\n",
        "print(\"\\n--- Model Detailed Object Detection Comparison ---\")\n",
        "for model_name, metrics in model_detailed_object_counts.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    if 'error' in metrics:\n",
        "        print(f\"  Status: Error - {metrics['error']}\")\n",
        "    else:\n",
        "        print(f\"  Total Objects Detected Across All Processed Frames: {metrics['total_objects_detected_across_video']}\")\n",
        "        print(f\"  Frames Processed: {metrics['frames_processed']}\")\n",
        "        print(\"  Detected Objects and Counts:\")\n",
        "        if metrics['object_class_counts']:\n",
        "            for class_name, count in metrics['object_class_counts'].items():\n",
        "                print(f\"    - {class_name}: {count}\")\n",
        "        else:\n",
        "            print(\"    No objects detected.\")\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}