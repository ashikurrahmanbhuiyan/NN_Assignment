{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":931,"output_embedded_package_id":"1lMNahXL39y4SEgBE4nZzaSkS62pxy5iK"},"id":"fgfWZGWLFmxK","executionInfo":{"status":"ok","timestamp":1751127696531,"user_tz":-360,"elapsed":455363,"user":{"displayName":"ASHIKUR RAHMAN","userId":"06132264115889812795"}},"outputId":"52b13b71-a151-47b3-e619-1e3f2a969b3a"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from tensorflow.keras.applications import VGG16, ResNet50\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.imagenet_utils import decode_predictions, preprocess_input\n","import cv2\n","\n","class AdversarialAnalyzer:\n","    def __init__(self, model_name='VGG16'):\n","\n","        if model_name == 'VGG16':\n","            self.model = VGG16(weights='imagenet')\n","            self.last_conv_layer = 'block5_conv3'\n","        else:\n","            self.model = ResNet50(weights='imagenet')\n","            self.last_conv_layer = 'conv5_block3_out'\n","\n","        self.model_name = model_name\n","\n","    def load_and_preprocess_image(self, img_path, target_size=(224, 224)):\n","        \"\"\"Load and preprocess image for the model\"\"\"\n","        img = image.load_img(img_path, target_size=target_size)\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = preprocess_input(img_array)\n","        return img_array\n","\n","    def create_adversarial_example_fgsm(self, img_array, target_class=None, epsilon=0.1):\n","        \"\"\"\n","        Create adversarial example using Fast Gradient Sign Method (FGSM)\n","\n","        Args:\n","            img_array: Input image array\n","            target_class: Target class for targeted attack (None for untargeted)\n","            epsilon: Perturbation strength\n","        \"\"\"\n","        img_tensor = tf.convert_to_tensor(img_array)\n","\n","        with tf.GradientTape() as tape:\n","            tape.watch(img_tensor)\n","            predictions = self.model(img_tensor)\n","\n","            if target_class is None:\n","                loss = tf.keras.losses.categorical_crossentropy(\n","                    predictions, predictions\n","                )\n","            else:\n","                target_one_hot = tf.one_hot(target_class, predictions.shape[-1])\n","                loss = -tf.keras.losses.categorical_crossentropy(\n","                    target_one_hot, predictions\n","                )\n","\n","        gradients = tape.gradient(loss, img_tensor)\n","        signed_grad = tf.sign(gradients)\n","        adversarial_img = img_tensor + epsilon * signed_grad\n","\n","        adversarial_img = tf.clip_by_value(adversarial_img, -1, 1)\n","\n","        return adversarial_img.numpy()\n","\n","    def grad_cam(self, img_array, class_idx, layer_name=None):\n","\n","        if layer_name is None:\n","            layer_name = self.last_conv_layer\n","\n","        grad_model = tf.keras.models.Model(\n","            [self.model.inputs],\n","            [self.model.get_layer(layer_name).output, self.model.output]\n","        )\n","\n","        with tf.GradientTape() as tape:\n","            conv_outputs, predictions = grad_model(img_array)\n","            class_output = predictions[:, class_idx]\n","\n","        grads = tape.gradient(class_output, conv_outputs)\n","\n","        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","        conv_outputs = conv_outputs[0]\n","        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n","        heatmap = tf.squeeze(heatmap)\n","\n","        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","\n","        return heatmap.numpy()\n","\n","    def grad_cam_softmax(self, img_array, class_idx):\n","        intermediate_layer = self.model.get_layer(self.last_conv_layer)\n","        grad_model = tf.keras.models.Model(\n","            [self.model.inputs],\n","            [intermediate_layer.output, self.model.output]\n","        )\n","\n","        with tf.GradientTape() as tape:\n","            conv_outputs, predictions = grad_model(img_array)\n","\n","            class_output = tf.nn.softmax(predictions)[:, class_idx]\n","\n","        grads = tape.gradient(class_output, conv_outputs)\n","        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","        conv_outputs = conv_outputs[0]\n","        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n","        heatmap = tf.squeeze(heatmap)\n","        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","\n","        return heatmap.numpy()\n","\n","    def integrated_gradients(self, img_array, class_idx, baseline=None, steps=50):\n","        if baseline is None:\n","            baseline = np.zeros_like(img_array)\n","\n","        img_array_nobatch = img_array[0]\n","        baseline_nobatch = baseline[0]\n","\n","        alphas = tf.linspace(start=0.0, stop=1.0, num=steps+1)\n","        interpolated_inputs = []\n","\n","        for alpha in alphas:\n","            interpolated_input = baseline_nobatch + alpha * (img_array_nobatch - baseline_nobatch)\n","            interpolated_inputs.append(interpolated_input)\n","\n","        interpolated_inputs_tensor = tf.stack(interpolated_inputs)\n","\n","        total_gradients = tf.zeros_like(img_array_nobatch, dtype=tf.float32)\n","\n","        batch_size = 32\n","\n","        for i in range(0, steps + 1, batch_size):\n","            batch_inputs = interpolated_inputs_tensor[i:i + batch_size]\n","\n","            with tf.GradientTape() as tape:\n","                tape.watch(batch_inputs)\n","                predictions = self.model(batch_inputs)\n","                class_outputs = predictions[:, class_idx]\n","\n","            batch_gradients = tape.gradient(class_outputs, batch_inputs)\n","            total_gradients = tf.add(total_gradients, tf.reduce_sum(batch_gradients, axis=0))\n","\n","        avg_gradients = total_gradients / (steps + 1)\n","        integrated_gradients = (img_array_nobatch - baseline_nobatch) * avg_gradients\n","\n","        return np.expand_dims(integrated_gradients.numpy(), axis=0)\n","\n","\n","    def integrated_gradients_pre_softmax(self, img_array, class_idx, baseline=None, steps=50):\n","        if baseline is None:\n","            baseline = np.zeros_like(img_array)\n","\n","        logits_model = tf.keras.models.Model(\n","            inputs=self.model.input,\n","            outputs=self.model.layers[-2].output\n","        )\n","\n","        img_array_nobatch = img_array[0]\n","        baseline_nobatch = baseline[0]\n","\n","        alphas = tf.linspace(start=0.0, stop=1.0, num=steps+1)\n","        interpolated_inputs = []\n","\n","        for alpha in alphas:\n","            interpolated_input = baseline_nobatch + alpha * (img_array_nobatch - baseline_nobatch)\n","            interpolated_inputs.append(interpolated_input)\n","\n","        interpolated_inputs_tensor = tf.stack(interpolated_inputs)\n","\n","        total_gradients = tf.zeros_like(img_array_nobatch, dtype=tf.float32)\n","        batch_size = 32\n","\n","        for i in range(0, steps + 1, batch_size):\n","            batch_inputs = interpolated_inputs_tensor[i:i + batch_size]\n","\n","            with tf.GradientTape() as tape:\n","                tape.watch(batch_inputs)\n","                logits = logits_model(batch_inputs)\n","                class_outputs = logits[:, class_idx]\n","\n","            batch_gradients = tape.gradient(class_outputs, batch_inputs)\n","            total_gradients = tf.add(total_gradients, tf.reduce_sum(batch_gradients, axis=0))\n","\n","\n","        avg_gradients = total_gradients / (steps + 1)\n","        integrated_gradients = (img_array_nobatch - baseline_nobatch) * avg_gradients\n","\n","        return np.expand_dims(integrated_gradients.numpy(), axis=0)\n","\n","\n","    def visualize_heatmap(self, img_array, heatmap, alpha=0.6):\n","        img = img_array[0].copy()\n","        img = (img - img.min()) / (img.max() - img.min())\n","\n","        heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n","        heatmap_resized = np.uint8(255 * heatmap_resized)\n","        heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n","        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n","\n","        overlayed = heatmap_colored * alpha + img * 255 * (1 - alpha)\n","        overlayed = np.uint8(overlayed)\n","\n","        return overlayed\n","\n","    def analyze_adversarial_example(self, img_path, epsilon=0.1, target_class=None):\n","        original_img = self.load_and_preprocess_image(img_path)\n","\n","        original_preds = self.model.predict(original_img)\n","        original_class = np.argmax(original_preds[0])\n","        original_confidence = np.max(original_preds[0])\n","\n","        print(f\"Original prediction: {decode_predictions(original_preds, top=1)[0][0][1]} \"\n","              f\"(confidence: {original_confidence:.3f})\")\n","\n","        adversarial_img = self.create_adversarial_example_fgsm(\n","            original_img, target_class, epsilon\n","        )\n","\n","        adv_preds = self.model.predict(adversarial_img)\n","        adv_class = np.argmax(adv_preds[0])\n","        adv_confidence = np.max(adv_preds[0])\n","\n","        print(f\"Adversarial prediction: {decode_predictions(adv_preds, top=1)[0][0][1]} \"\n","              f\"(confidence: {adv_confidence:.3f})\")\n","\n","        fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n","\n","        original_gradcam = self.grad_cam(original_img, original_class)\n","        original_gradcam_softmax = self.grad_cam_softmax(original_img, original_class)\n","        original_ig = self.integrated_gradients(original_img, original_class)\n","        original_ig_pre_softmax = self.integrated_gradients_pre_softmax(original_img, original_class)\n","\n","        adv_gradcam = self.grad_cam(adversarial_img, adv_class)\n","        adv_gradcam_softmax = self.grad_cam_softmax(adversarial_img, adv_class)\n","        adv_ig = self.integrated_gradients(adversarial_img, adv_class)\n","        adv_ig_pre_softmax = self.integrated_gradients_pre_softmax(adversarial_img, adv_class)\n","\n","        axes[0, 0].imshow((original_img[0] + 1) / 2)\n","        axes[0, 0].set_title('Original Image')\n","        axes[0, 0].axis('off')\n","\n","        axes[0, 1].imshow(self.visualize_heatmap(original_img, original_gradcam))\n","        axes[0, 1].set_title('Original: Grad-CAM')\n","        axes[0, 1].axis('off')\n","\n","        axes[0, 2].imshow(self.visualize_heatmap(original_img, original_gradcam_softmax))\n","        axes[0, 2].set_title('Original: Grad-CAM (Softmax)')\n","        axes[0, 2].axis('off')\n","\n","        ig_vis = np.mean(np.abs(original_ig[0]), axis=2) # Use original_ig[0] to get the single image\n","        ig_vis = (ig_vis - ig_vis.min()) / (ig_vis.max() - ig_vis.min())\n","        axes[0, 3].imshow(self.visualize_heatmap(original_img, ig_vis))\n","        axes[0, 3].set_title('Original: Integrated Gradients')\n","        axes[0, 3].axis('off')\n","\n","        axes[1, 0].imshow((adversarial_img[0] + 1) / 2)\n","        axes[1, 0].set_title('Adversarial Image')\n","        axes[1, 0].axis('off')\n","\n","        axes[1, 1].imshow(self.visualize_heatmap(adversarial_img, adv_gradcam))\n","        axes[1, 1].set_title('Adversarial: Grad-CAM')\n","        axes[1, 1].axis('off')\n","\n","        axes[1, 2].imshow(self.visualize_heatmap(adversarial_img, adv_gradcam_softmax))\n","        axes[1, 2].set_title('Adversarial: Grad-CAM (Softmax)')\n","        axes[1, 2].axis('off')\n","\n","        adv_ig_vis = np.mean(np.abs(adv_ig[0]), axis=2) # Use adv_ig[0] to get the single image\n","        adv_ig_vis = (adv_ig_vis - adv_ig_vis.min()) / (adv_ig_vis.max() - adv_ig_vis.min())\n","        axes[1, 3].imshow(self.visualize_heatmap(adversarial_img, adv_ig_vis))\n","        axes[1, 3].set_title('Adversarial: Integrated Gradients')\n","        axes[1, 3].axis('off')\n","\n","        ig_pre_softmax_vis = np.mean(np.abs(original_ig_pre_softmax[0]), axis=2)\n","        ig_pre_softmax_vis = (ig_pre_softmax_vis - ig_pre_softmax_vis.min()) / (ig_pre_softmax_vis.max() - ig_pre_softmax_vis.min())\n","        axes[2, 0].imshow(self.visualize_heatmap(original_img, ig_pre_softmax_vis))\n","        axes[2, 0].set_title('Original: IG (Pre-softmax)')\n","        axes[2, 0].axis('off')\n","\n","        adv_ig_pre_softmax_vis = np.mean(np.abs(adv_ig_pre_softmax[0]), axis=2)\n","        adv_ig_pre_softmax_vis = (adv_ig_pre_softmax_vis - adv_ig_pre_softmax_vis.min()) / (adv_ig_pre_softmax_vis.max() - adv_ig_pre_softmax_vis.min())\n","        axes[2, 1].imshow(self.visualize_heatmap(adversarial_img, adv_ig_pre_softmax_vis))\n","        axes[2, 1].set_title('Adversarial: IG (Pre-softmax)')\n","        axes[2, 1].axis('off')\n","\n","        perturbation = adversarial_img - original_img\n","        perturbation_vis = np.mean(np.abs(perturbation[0]), axis=2)\n","        perturbation_vis = (perturbation_vis - perturbation_vis.min()) / (perturbation_vis.max() - perturbation_vis.min())\n","        axes[2, 2].imshow(perturbation_vis, cmap='hot')\n","        axes[2, 2].set_title('Adversarial Perturbation')\n","        axes[2, 2].axis('off')\n","\n","        attention_diff = np.abs(adv_gradcam - original_gradcam)\n","        axes[2, 3].imshow(attention_diff, cmap='hot')\n","        axes[2, 3].set_title('Grad-CAM Difference')\n","        axes[2, 3].axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        print(\"\\n=== Quantitative Analysis ===\")\n","        print(f\"L2 norm of perturbation: {np.linalg.norm(perturbation):.4f}\")\n","        print(f\"Max perturbation: {np.max(np.abs(perturbation)):.4f}\")\n","\n","        original_attention_flat = original_gradcam.flatten()\n","        adv_attention_flat = adv_gradcam.flatten()\n","        attention_correlation = np.corrcoef(original_attention_flat, adv_attention_flat)[0, 1]\n","        print(f\"Grad-CAM correlation (original vs adversarial): {attention_correlation:.4f}\")\n","\n","        gradcam_softmax_diff = np.mean(np.abs(original_gradcam_softmax - original_gradcam))\n","        ig_softmax_diff = np.mean(np.abs(ig_vis - ig_pre_softmax_vis))\n","\n","        print(f\"Grad-CAM difference (softmax vs pre-softmax): {gradcam_softmax_diff:.4f}\")\n","        print(f\"IG difference (softmax vs pre-softmax): {ig_softmax_diff:.4f}\")\n","\n","        return {\n","            'original_img': original_img,\n","            'adversarial_img': adversarial_img,\n","            'original_gradcam': original_gradcam,\n","            'adv_gradcam': adv_gradcam,\n","            'original_ig': original_ig,\n","            'adv_ig': adv_ig,\n","            'attention_correlation': attention_correlation\n","        }\n","\n","if __name__ == \"__main__\":\n","    analyzer = AdversarialAnalyzer('VGG16')  # or 'ResNet50'\n","\n","    img_path = '/content/istockphoto-91843294-612x612.jpg'\n","    results = analyzer.analyze_adversarial_example(img_path, epsilon=0.1)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}